---
layout: post
title: "[DSLAB] RNN"

categories:
  - DSLAB
  - 2. 자연어 처리와 딥러닝

tags:
  - [NLP, RNN, Deep learning Model]
---

`Recurrent Neural Network(RNN)`은 기본적으로 시퀀스 데이터가 입력 또는 출력으로 주어진 데이터를 처리하는데 특화된 신경망 구조로 현재 타임스텝에 대해 이전 스텝까지의 정보를
기반으로 예측값을 산출하는 딥러닝 모델이다.

### RNN의 구조

---
![이미지](https://images.velog.io/images/yuns_u/post/ccbb28ea-fa08-4d23-804e-419e6f578e4b/image.png)
`RNN`은 위의 그림처럼 데이터 x1, x2 ... xT은 각 타임 스텝의 입력으로서 순차적으로 들어가게 된다. 그래서 매 타임 스텝마다 RNN모듈이 전 타임 스텝까지 
계산해놓은 hidden state 벡터와 현재 들어온 입력 데이터 벡터 xt를 결합해서 현재 타임스텝의 hidden state인 ht를 계산하게 된다.
<br/>

이때 RNN이라고 불리는 이유는 서로 다른 타임 스텝에서 들어오는 입력 데이터를 처리할 때 동일한 파라미터를 가져 모듈이 반복적으로 등장해 순환하는 형태를
가지고 있기 때문이다.

### RNN의 동작 원리

---

![이미지](https://i.imgur.com/s8nYcww.png)

+ ht = 현재의 새로운 hidden-state vector
+ ht-1 = 과거 hidden-state vector
+ yt = output vector
+ W = RNN의 파라미터
+ xt = 입력 데이터

RNN은 먼저 입력 데이터값 xt와 직전 hidden-state vector값인 ht-1을 이용한 ht를 구하는 함수를 통해 매 타임스텝마다 hidden-state를
구하게 된다. 그 후 앞서 구한 ht로 yt를 계산해 output vector를 만들어 출력하게 된다. 여기서 RNN의 중요한 가장 중요한 특징으로는 매 타임 스텝마다
RNN모듈을 정의하는 파라미터 W는 모든 타임 스텝에서 동일한 값을 공유한다는 사실이다.

### RNN의 유형

---

`RNN`에는 `One-to-one`, `One-to-many`, `Many-to-one`, `Many-to-many`의 다른 유형들이 있다. 각 유형들은 해결하고자 하는 문제에 따라 다르게
사용된다.

![이미지](https://doll6777.github.io/assets/2019-10-02-char-rnn-seedbank/diags.jpeg)

+ One-to-one 
  + 가장 기본적인 형태의 RNN으로 Vanilla RNN으로 하나의 입력을 받아 하나의 출력을 낸다.
  + 하나의 글자를 입력했을 때 하나의 글자를 예측하는 경우이다.
+ One-to-many
  + 하나의 입력을 받아 여러개의 출력을 내는 것이다.
  + 하나의 이미지를 입력으로 주게되면 사진의 제목을 출력하는 Image Captioning이 대표적인 예시이다.
+ Many-to-one
  + 단어 시퀀스에 대해 하나의 출력을 낸다.
  + 입력 문서가 긍정적인지 부정적인지 판별하는 Sentiment Classification에 사용된다.
  + 메일이 정상 메일인지 스팸 메일인지 판별하는 스팸 메일 분류에 사용된다.
+ Many-to-Many
  + 문장을 입력하면 대답 문장을 출력한다.
  + 기계어 번역(Machine Translation)에 사용된다.

### Character-Level Language Model

---

요즘 자연어 처리에서의 최신 트렌드는 GPT와 같은 거대언어모델(LLM)이라고 할 수 있다. 하지만 LLM을 알기 위해서는 먼저 언어모델을 알아야 한다.
언어 모델(Language Model)은 이전에 등장한 문자열을 기반으로 다음에 등장할 단어를 예측하는 테스크이다. 그 중에서도 간단한 Character-level
Language Model은 문자 단위로 문자를 입력 받고 다음에 올 문자를 예측하는 모델이다. 예를 들어 hello라는 단어에서 h가 입력되면 e를 예측해
출력하고 e가 다시 입력되어 l을 예측해 출력하는 것이다.

![이미지](https://velog.velcdn.com/images%2Fpseeej%2Fpost%2Ff7839f7d-9261-494b-aaa4-d2b5fd1a47e2%2Fimage.png)

여기서 각 타임스텝별로 output layer를 통해 차원이 4(유니크한 문자의 개수) 벡터를 출력해주는데 이를 logit이라고 부르며, softmax layer를
통과시키면 `One-hot vector` 형태의 출력값이 나오게 된다.

![이미지](/assets/img/2024-01-10-RNN/img_1.png)

그래서 출력된 `One-hot vector`를 통해 만들어놓은 `Vocabulary`에 맞는 문자를 출력하는 것이다. 그래서 모델이 훈련 과정을 거치면서
파라미터값이 조정되고 맞는 문자를 출력하도록 훈련되는 모델인 것이다.

EX)

![이미지](https://cphinf.pstatic.net/mooc/20220930_270/1664492807464wgs8P_PNG/mceclip0.png)

